{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [IAPR][iapr]: Lab 1 ‒  Image segmentation\n",
    "\n",
    "\n",
    "**Group ID:** xx\n",
    "\n",
    "**Author 1 (sciper):** Student Name 1 (xxxxx)  \n",
    "**Author 2 (sciper):** Student Name 2 (xxxxx)   \n",
    "**Author 3 (sciper):** Student Name 3 (xxxxx)   \n",
    "\n",
    "**Release date:** 05.03.2025   \n",
    "**Due date:** 19.03.2025 (11:59 pm)\n",
    "\n",
    "\n",
    "## Key Submission Guidelines:\n",
    "- **Before submitting your notebook, <span style=\"color:red;\">rerun</span> it from scratch!** Go to: `Kernel` > `Restart & Run All`  \n",
    "- **Only groups of three will be accepted**, except in exceptional circumstances.  \n",
    "- **You are not allowed to use any libraries** other than those provided in this notebook.  \n",
    "- **Failure to follow these guidelines may result in point deductions** during grading.  \n",
    "\n",
    "\n",
    "[iapr]: https://github.com/LTS5/iapr2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check is at least python 3.9\n",
    "import sys \n",
    "assert (sys.version_info.major == 3) and (sys.version_info.minor >= 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install numpy -q\n",
    "!pip install matplotlib -q\n",
    "!pip install scikit-image -q\n",
    "!pip install pillow -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import main packages\n",
    "from utils.lab_01_utils import *\n",
    "from skimage.color import rgb2hsv, rgb2gray\n",
    "from skimage.morphology import closing, opening, disk, remove_small_holes, remove_small_objects, binary_dilation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Introduction\n",
    "\n",
    "\n",
    "In this lab, we will be working with histological data. Histological images are created from tissue samples that are digitized using high-resolution scanners. Without preparation, human tissues lack visual contrast and have poor tissue differentiations. To overcome this issue, clinical institutes use chemical staining to artificially enhance contrast. The most famous one is called HE (hematoxylin and eosin) staining. Hematoxylin stains tissue nuclei with a deep purple while eosin focuses more on extracellular matrix components with a pink stain.\n",
    "\n",
    "Before running the following code make sure that the images are located as follows:\n",
    "\n",
    "```code\n",
    "├── labs\n",
    "|   ├── utils\n",
    "|   |   └── lab_01_utils.py\n",
    "|   └── lab_01_iapr.ipynb\n",
    "└── data\n",
    "    └── data_lab_01\n",
    "        ├── tcga_crc_example.png\n",
    "        └── tcga_blood_example.png\n",
    "```\n",
    "**⚠️ DO NOT CHANGE THIS CONFIGURATION, AS WE WILL RERUN YOUR NOTEBOOK USING THIS EXACT STRUCTURE!**\n",
    "\n",
    "By running the following cells you will display a HE histological sample of a colorectal cancer case. It is composed of 3 main entities:\n",
    "* **Mucin**: Grayish mucus that is secreted by the body. The presence of a tumor tends to increase its presence. \n",
    "* **Tumor**: Dark purple aggregates (hematoxylin). Mainly composed of cancerous cells.\n",
    "* **Other**: Mixture of other cells such as stromal or lymphocytes. It appears mainly pink (eosin) but is dotted with nuclei (purple)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_he = show_introduction_figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Part 1 - Segmentation [16 pts]\n",
    "\n",
    "## Part 1.1 - RGB (3 pts)\n",
    "\n",
    "**Q1 (1 pts)**: In this section, you will have to complete the function `extract_rgb_channels`. The function should extract and return red, blue, and green channels from the input image `img`. Your function will be fed to `plot_colors_histo` to plot the distribution of the colors in the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_rgb_channels(img):\n",
    "    \"\"\"\n",
    "    Extract RGB channels from the input image.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    img: np.ndarray (M, N, C)\n",
    "        Input image of shape MxN and C channels.\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    data_red: np.ndarray (M, N)\n",
    "        Red channel of input image\n",
    "    data_green: np.ndarray (M, N)\n",
    "        Green channel of input image\n",
    "    data_blue: np.ndarray (M, N)\n",
    "        Blue channel of input image\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the shape of the input image\n",
    "    M, N, _ = np.shape(img)\n",
    "\n",
    "    # Define default values for RGB channels\n",
    "    data_red = np.zeros((M, N))\n",
    "    data_green = np.zeros((M, N))\n",
    "    data_blue = np.zeros((M, N))\n",
    "\n",
    "    data_red = img[:, :, 0]\n",
    "    data_green = img[:, :, 1]\n",
    "    data_blue = img[:, :, 2] \n",
    "\n",
    "    return data_red, data_green, data_blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "############################ TEST ##############################\n",
    "################################################################\n",
    "\n",
    "plot_colors_histo(\n",
    "    img = img_he,\n",
    "    func = extract_rgb_channels,\n",
    "    labels = [\"Red\", \"Green\", \"Blue\"],\n",
    ")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.hist(rgb2gray(img_he).ravel(), bins=256)\n",
    "plt.title('grayscale histogram')\n",
    "plt.show()\n",
    "\n",
    "R,G,B = extract_rgb_channels(img_he)\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.hist(R.ravel(), bins=256)\n",
    "plt.title('red value histogram')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.hist(G.ravel(), bins=256)\n",
    "plt.title('green value histogram')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.hist(B.ravel(), bins=256)\n",
    "plt.title('blue histogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the result of the plot above\n",
    "\n",
    "* **Q2 (1 pts)**: Do you think you can find a simple manual thresholding approach to isolate the tumor components? (Justify)\n",
    "    * **Answer**:The grayscale values obtained are not very discriminative. However, it is clearly observed that light purple pixels and dark purple pixels accumulate at grayscale values of 0.78 and 0.40, respectively. One can try thresholding to segment the image. Therefore, manual thresholding is applicable but not very effective. Also, note that the simple thresholding method masks the background from objects. Since some dark purple pixels appear as noise in other cells, thresholding alone cannot effectively mask those pixels.\n",
    "* **Q3 (1 pts)**: Implement your own manual thresholding in `apply_rgb_threshold` to estimate the tumor location. Use the function `plot_thresholded_image` below to display your estimation results. Do you think your estimation is reliable? (justify)\n",
    "    * **Answer**: Mucin in the image appears to be masked since its grayscale value is closer to \"1\" (assuming grayscale values are normalized). After applying the thresholding operation, those areas are shown as black because their grayscale value is higher than \"0.41\". In addition, the light purple pixels (other cells) are also shown as black. The darker pixels remain visible, and tumor cells become somewhat detectable but not very clear. Also, note that since there are dark purple pixels present in other cells, they remain visible, resulting in an image with white noise. The resulting estimation will not lead to false negatives, making it not entirely unreliable, but will introduce many false positives, making it impractical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_rgb_threshold(img):\n",
    "    \"\"\"\n",
    "    Apply threshold to input image. (R, G, B)\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    img: np.ndarray (M, N, C)\n",
    "        Input image of shape MxN and C channels.    \n",
    "    Return\n",
    "    ------\n",
    "    img_th: np.ndarray (M, N)\n",
    "        Thresholded image.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # r_low \n",
    "    # r_high\n",
    "    # g_low\n",
    "    # g_high\n",
    "    # b_low\n",
    "    # b_high\n",
    "\n",
    "    thres_low = 0.41\n",
    "    thresh_high = 1\n",
    "\n",
    "    # Define the default value for the input image\n",
    "    M, N, C = np.shape(img)\n",
    "    img_th = np.zeros((M, N))\n",
    "    img_th = rgb2gray(img)\n",
    "\n",
    "    # Use the previous function to extract RGB channels\n",
    "    data_red, data_green, data_blue = extract_rgb_channels(img=img)\n",
    "    \n",
    "\n",
    "    # r_mask =  data_red >= r_low & data_red <= r_high\n",
    "    # g_mask =  data_green >= g_low & data_green <= g_high\n",
    "    # b_mask =  data_blue >= b_low & data_blue <= b_high\n",
    "    \n",
    "    # mask = r_mask & g_mask & b_mask\n",
    "    mask = (img_th >= thres_low) & (img_th <= thresh_high)\n",
    "    img_th[ mask ] = 0 \n",
    "    return  img_th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "############################ TEST ##############################\n",
    "################################################################\n",
    "\n",
    "# Plot best RGB thresholding\n",
    "plot_thresholded_image(img=img_he, func=apply_rgb_threshold, title=\"Best RGB Threshold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.2 - Other colorspaces (3 pts)\n",
    "\n",
    "So far we used the standard RGB colorspace to apply our thresholding. In this section, you will convert the image to a different color space. \n",
    "\n",
    "* **Q1 (1 pts)**: Use the function `rgb2hsv` from the skimage package ([see doc](https://scikit-image.org/docs/stable/auto_examples/color_exposure/plot_rgb_to_hsv.html)) to convert the input image from RGB to HSV in function `extract_hsv_channels`.\n",
    "* **Q2 (1 pts)**: Can you see any difference between the use of the RGB or HSV space? (justify)\n",
    "    * **Answer**: The correlation between the pixel values is altered. In RGB, pixels are highly correlated, as observed in scatter plots where color intensity values show a strong linear relationship. In contrast, in the HSV space, the correlation structure changes significantly—hue, saturation, and value describe colors in a way that is closer to human perception. Notably, hue is less linearly correlated with the other channels, as it represents color independent of intensity. By using the HSV space, we should obtain better image segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hsv_channels(img):\n",
    "    \"\"\"\n",
    "    Extract HSV channels from the input image.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    img: np.ndarray (M, N, C)\n",
    "        Input image of shape MxN and C channels.\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    data_h: np.ndarray (M, N)\n",
    "        Hue channel of input image\n",
    "    data_s: np.ndarray (M, N)\n",
    "        Saturation channel of input image\n",
    "    data_v: np.ndarray (M, N)\n",
    "        Value channel of input image\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the shape of the input image\n",
    "    M, N, C = np.shape(img)\n",
    "\n",
    "    img = rgb2hsv(img)\n",
    "\n",
    "    # Define default values for HSV channels\n",
    "    data_h = np.zeros((M, N))\n",
    "    data_s = np.zeros((M, N))\n",
    "    data_v = np.zeros((M, N))\n",
    "\n",
    "    data_h = img[:, :, 0]\n",
    "    data_s = img[:, :, 1]\n",
    "    data_v = img[:, :, 2]\n",
    "\n",
    "    return data_h, data_s, data_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "############################ TEST ##############################\n",
    "################################################################\n",
    "\n",
    "# Call plotting function with your implemented function\n",
    "plot_colors_histo(\n",
    "    img = img_he,\n",
    "    func = extract_hsv_channels,\n",
    "    labels = [\"Hue\", \"Saturation\", \"Value\"],\n",
    ")\n",
    "\n",
    "H,S,V = extract_hsv_channels(img_he)\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.hist(H.ravel(), bins=256)\n",
    "plt.title('hue value histogram')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.hist(S.ravel(), bins=256)\n",
    "plt.title('saturation value histogram')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.hist(V.ravel(), bins=256)\n",
    "plt.title('value histogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Q3 (1 pts)**: Based on your results, try again to find the best manual threshold in function `apply_hsv_threshold`. Do you think your estimation is reliable? (justify)\n",
    "    * **Answer**: As mentioned, HSV is a better representation for image segmentation. However, since running the expectation algorithm to fit a Gaussian mixture model with two Gaussians is not available, detecting a perfect threshold is not possible. Furthermore, the results are similar to those obtained with segmentation in the RGB space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_hsv_threshold(img):\n",
    "    \"\"\"\n",
    "    Apply threshold to the input image in hsv colorspace.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    img: np.ndarray (M, N, C)\n",
    "        Input image of shape MxN and C channels.\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    img_th: np.ndarray (M, N)\n",
    "        Thresholded image.\n",
    "    \"\"\"\n",
    "\n",
    "    #Fill in HSV threshold 0-1\n",
    "    th_low = 270/360\n",
    "    th_high = 310/360\n",
    "\n",
    "    ts_low = 0.34\n",
    "    ts_high = 0.47\n",
    "\n",
    "    tv_low = 0.40\n",
    "    tv_high = 0.50\n",
    "\n",
    "\n",
    "    # Define the default value for the input image\n",
    "    M, N, C = np.shape(img)\n",
    "    #img_th = np.zeros((M, N))\n",
    "    img_th = img.copy()\n",
    "\n",
    "    # Use the previous function to extract HSV channels\n",
    "    data_h, data_s, data_v = extract_hsv_channels(img=img)\n",
    "\n",
    "    h_mask =  (data_h >= th_low) & (data_h <= th_high)\n",
    "    s_mask =  (data_s >= ts_low) & (data_s <= ts_high)\n",
    "    v_mask =  (data_v >= tv_low) & (data_v <= tv_high)\n",
    "\n",
    "\n",
    "    #mask = h_mask & s_mask & v_mask\n",
    "    mask = h_mask &  s_mask | v_mask\n",
    "    \n",
    "    img_th[ np.logical_not(mask) ] = 0\n",
    "\n",
    "\n",
    "    return  rgb2gray(img_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "############################ TEST ##############################\n",
    "################################################################\n",
    "\n",
    "# Find threshold(s) in the hsv channels\n",
    "img_th=apply_hsv_threshold(img_he)\n",
    "\n",
    "plot_thresholded_image(img=img_he, func=apply_hsv_threshold, title=\"Threshold in HSV color space\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.3 - Morphology (5 pts)\n",
    "\n",
    "To proceed, we will use your results from the previous thresholding (namely `apply_hsv_threshold`) as the starting point. In this exercise, we will try to clean the masked images using morphology to get a better estimation of the tumor area.\n",
    "\n",
    "* **Q1 (1 pts)**: Implement the functions `apply_closing` and `apply_opening` with operations `closing` ([see doc](https://scikit-image.org/docs/stable/api/skimage.morphology.html#skimage.morphology.closing)), `opening` ([see doc](https://scikit-image.org/docs/stable/api/skimage.morphology.html#skimage.morphology.opening)) using the disk sizes arguments ([see doc](https://scikit-image.org/docs/stable/api/skimage.morphology.html#skimage.morphology.disk)).\n",
    "* **Q2 (1 pts)**: We test disk sizes: $1, 2, 5, 10$. Comment on the quality of the results.\n",
    "    * **Answer**: In our case, closing produces better results than opening because, after thresholding, the image contains small holes and gaps within the contours, which should not be present. Closing (dilation followed by erosion) effectively fills these unwanted holes, whereas opening worsens them. Beyond size 2, opening completely removes almost all objects. \n",
    "    Disk size 1 is too small to have a noticeable effect. Small holes and noise remain. Disk size 2 is optimal, as small holes are removed while preserving the tumor's shape. Larger sizes merge objects that should remain separate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_closing(img_th, disk_size):\n",
    "    \"\"\"\n",
    "    Apply closing to input mask image using disk shape.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    img_th: np.ndarray (M, N)\n",
    "        Image mask of size MxN.\n",
    "    disk_size: int\n",
    "        Size of the disk to use for opening\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    img_closing: np.ndarray (M, N)\n",
    "        Image after closing operation\n",
    "    \"\"\"\n",
    "\n",
    "    # Define default value for output image\n",
    "    img_closing = np.zeros_like(img_th)\n",
    "\n",
    "    img_closing = closing(img_th, disk(disk_size))\n",
    "\n",
    "    return img_closing\n",
    "\n",
    "\n",
    "def apply_opening(img_th, disk_size):\n",
    "    \"\"\"\n",
    "    Apply opening to input mask image using disk shape.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    img_th: np.ndarray (M, N)\n",
    "        Image mask of size MxN.\n",
    "    disk_size: int\n",
    "        Size of the disk to use for opening\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    img_opening: np.ndarray (M, N)\n",
    "        Image after opening operation\n",
    "    \"\"\"\n",
    "\n",
    "    # Define default value for output image\n",
    "    img_opening = np.zeros_like(img_th)\n",
    "\n",
    "    img_opening = opening(img_th, disk(disk_size))\n",
    "\n",
    "    return img_opening\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "############################ TEST ##############################\n",
    "################################################################\n",
    "\n",
    "def plot_close_open(img_th, apply_closing, apply_opening):\n",
    "    disk_size = [1, 2, 5, 10]\n",
    "    fig, axs = plt.subplots(2, 4, figsize=(20, 10))\n",
    "    for i, size in enumerate(disk_size):\n",
    "        img_closing = apply_closing(img_th, size)\n",
    "        img_opening = apply_opening(img_th, size)\n",
    "        axs[0, i].imshow(img_closing, cmap=\"gray\")\n",
    "        axs[0, i].set_title(f\"Closing with disk size {size}\")\n",
    "        axs[1, i].imshow(img_opening, cmap=\"gray\")\n",
    "        axs[1, i].set_title(f\"Opening with disk size {size}\")\n",
    "    plt.show()\n",
    "\n",
    "plot_close_open(img_th, apply_closing, apply_opening)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Q3 (1 pts)** Implement the functions `remove_holes` and `remove_objects` using operations [remove_small_holes](https://scikit-image.org/docs/stable/api/skimage.morphology.html#skimage.morphology.remove_small_holes), [remove_small_objects](https://scikit-image.org/docs/stable/api/skimage.morphology.html#skimage.morphology.remove_small_objects) from skimage package, respectively.\n",
    "* **Q4 (1 pts)** We test the functions using area sizes: $10, 50, 100$, and $500$. Comment on the quality of the results.\n",
    "    * **Answer**: Removing small holes smoothed the tumor's interior by filling unwanted gaps, with an area size of 100 providing the best balance. Smaller sizes (10, 50) left some holes, while 500 was too aggressive, over-smoothing holes that should remain . Similarly, removing small objects effectively eliminated unwanted healthy cell structures that remained after thresholding, with 100 being the most effective size. While it left some unwanted objects, 500 was too aggressive, removing parts of the tumor tissue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_holes(img_th, size):\n",
    "    \"\"\"\n",
    "    Remove holes from input image that are smaller than size argument.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    img_th: np.ndarray (M, N)\n",
    "        Image mask of size MxN.\n",
    "    size: int\n",
    "        Minimal size of holes\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    img_holes: np.ndarray (M, N)\n",
    "        Image after remove holes operation\n",
    "    \"\"\"\n",
    "\n",
    "    # Define default value for input image\n",
    "    img_th = img_th > 0\n",
    "\n",
    "    img_holes = remove_small_holes(img_th, size)\n",
    "\n",
    "    return img_holes\n",
    "\n",
    "\n",
    "def remove_objects(img_th, size):\n",
    "    \"\"\"\n",
    "    Remove objects from input image that are smaller than size argument.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    img_th: np.ndarray (M, N)\n",
    "        Image mask of size MxN.\n",
    "    size: int\n",
    "        Minimal size of objects\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    img_obj: np.ndarray (M, N)\n",
    "        Image after remove small objects operation\n",
    "    \"\"\"\n",
    "\n",
    "    # Define default value for input image\n",
    "    img_th = img_th > 0\n",
    "\n",
    "    img_obj = remove_small_objects(img_th, size)\n",
    "\n",
    "    return img_obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "############################ TEST ##############################\n",
    "################################################################\n",
    "\n",
    "def plot_remove_holes_objects(img, remove_holes, remove_objects):\n",
    "    area_sizes = [10, 50, 100, 500]\n",
    "    fig, axs = plt.subplots(2, len(area_sizes), figsize=(20, 10))\n",
    "    for i, size in enumerate(area_sizes):\n",
    "        img_holes = remove_holes(img, size)\n",
    "        img_obj = remove_objects(img, size)\n",
    "        axs[0, i].imshow(img_holes, cmap=\"gray\")\n",
    "        axs[0, i].set_title(f\"Remove holes with size {size}\")\n",
    "        axs[1, i].imshow(img_obj, cmap=\"gray\")\n",
    "        axs[1, i].set_title(f\"Remove objects with size {size}\")\n",
    "    plt.show()\n",
    "\n",
    "#plot_remove_holes_objects(close_img, remove_holes, remove_objects)\n",
    "plot_remove_holes_objects(img_th, remove_holes, remove_objects)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Q5 (1 pts)** Based on your previous results, implement the function `apply_morphology` that combines morphology functions to improve your tumor detection results from HSV thresholding. In this exercise, we prioritize having a higher number of false positives rather than false negatives, as mistakenly labeling non-tumor regions as tumors (over-segmentation) is preferable to missing actual tumor regions, which could lead to undetected cancerous areas and delayed treatment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_morphology(img_th):\n",
    "    \"\"\"\n",
    "    Apply morphology to thresholded image\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    img_th: np.ndarray (M, N)\n",
    "        Image mask of size MxN.\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    img_morph: np.ndarray (M, N)\n",
    "        Image after morphological operations\n",
    "    \"\"\"\n",
    "    img_morph = np.zeros_like(img_th)\n",
    "    img_th = apply_closing(img_th, 2)\n",
    "    img_th[img_th > 0] = 1\n",
    "    img_th = img_th.astype(bool)\n",
    "    img_morph = remove_holes(img_th, 100)\n",
    "    img_morph = remove_objects(img_morph, 500)\n",
    "    img_morph = apply_opening(img_morph, 2)\n",
    "    #img_morph = apply_closing(img_morph, 2)\n",
    "    \n",
    "    return img_morph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "############################ TEST ##############################\n",
    "################################################################\n",
    "\n",
    "img_best_morpho = apply_morphology(apply_hsv_threshold(img_he))\n",
    "plot_morphology_best(\n",
    "    img_source=img_he,\n",
    "    img_best=img_best_morpho,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.4 - Region Growing (4 pts)\n",
    "\n",
    "* **Q1 (3 pts)** In this section we ask you to implement from scratch your own `region_growing` function to detect the tumor area. The function should take as input an RGB image, seeds that are manual initialization points in the tumor area, and the maximum number of iterations to perform. Note that the function also includes the kwargs argument. You can use it to add additional parameters to your function if needed (see [doc kwargs](https://book.pythontips.com/en/latest/args_and_kwargs.html)). Importantly, for timing reasons, a single explicit for loop on iterations is expected. An explicit for loop on pixels or neighbours will be accepted but penalised by 1 point. Use numpy tools to succeed.\n",
    "* **Q2 (1 pts)** Your function is then used to perform region growing using multiple iterations. Comment on the quality of the results based on the number of iterations performed as well as the running time.\n",
    "    * **Answer**: As we increase the number of iterations, the region identified as the tumor gets bigger. The basic algorithm starts from seed points and checks neighboring pixels to see if their values vary within a given threshold. If they do, those pixels become the next active points (the same procedure applied to the initial points is then applied to these active points), while the ones used in the previous iteration are no longer considered. As the maximum number of iterations increases, more of the region gets covered. Thanks to this method elimination of white noise is possible, and only connected objects are indicated at the end of the algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_growing(\n",
    "    seeds: list[tuple],\n",
    "    img: np.ndarray,\n",
    "    n_max: int = 10,\n",
    "    **kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    Run region growing on input image using seed points.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    seeds: list of tuple\n",
    "        List of seed points\n",
    "    img: np.ndarray (M, N, C)\n",
    "        RGB image of size M, N, C\n",
    "    n_max: int\n",
    "        Number maximum of iterations before stopping algorithm\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    rg: np.ndarray (M, N)\n",
    "        Image after region growing has been performed\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    threshold = kwargs['threshold']\n",
    "\n",
    "    if(not kwargs['isGrayScale']):\n",
    "        gray_img = rgb2gray(img)\n",
    "    else:\n",
    "        gray_img = img\n",
    "    \n",
    "    M,N = gray_img.shape\n",
    "    rg = np.zeros((M, N)).astype(bool)\n",
    "    seeds_numpy = np.array(seeds)\n",
    "    seed_intensity = gray_img[seeds_numpy[:,0],seeds_numpy[:,1]]\n",
    "    queue = np.zeros((M, N), dtype=bool)\n",
    "    queue[seeds_numpy[:, 0], seeds_numpy[:, 1]] = True\n",
    "    neighbor_offsets = np.array([\n",
    "        [-1, 0], [1, 0], [0, -1], [0, 1]  # Up, Down, Left, Right\n",
    "    ])\n",
    "\n",
    "    for i in range(n_max):\n",
    "        active_pixels = np.argwhere(queue)\n",
    "\n",
    "        if active_pixels.size == 0:\n",
    "            break  # Stop if no more pixels to process\n",
    "\n",
    "        # Reset queue\n",
    "        queue.fill(False)\n",
    "\n",
    "        # Get neighboring positions\n",
    "        neighbors = (active_pixels[:, None, :] + neighbor_offsets).reshape(-1, 2)\n",
    "\n",
    "        # Keep only valid positions\n",
    "        valid_mask = (\n",
    "            (neighbors[:, 0] >= 0) & (neighbors[:, 0] < M) &\n",
    "            (neighbors[:, 1] >= 0) & (neighbors[:, 1] < N)\n",
    "        )\n",
    "        neighbors = neighbors[valid_mask]\n",
    "\n",
    "        # Compute intensity difference\n",
    "        neighbor_intensity = gray_img[neighbors[:, 0], neighbors[:, 1]]\n",
    "        diff = np.abs(neighbor_intensity - seed_intensity.mean())\n",
    "\n",
    "        # Select pixels within the threshold and not already part of the region\n",
    "        valid_neighbors = neighbors[(diff <= threshold) & (~rg[neighbors[:, 0], neighbors[:, 1]])]\n",
    "\n",
    "\n",
    "        # Update region and queue\n",
    "        rg[valid_neighbors[:, 0], valid_neighbors[:, 1]] = True\n",
    "        queue[valid_neighbors[:, 0], valid_neighbors[:, 1]] = True\n",
    "\n",
    "    \n",
    "    # ------------------\n",
    "    # Your code here ... \n",
    "    # ------------------\n",
    "                    \n",
    "    return rg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add you additional arguments in the dictionary below\n",
    "kwargs = {'threshold':0.1,'isGrayScale':False}\n",
    "# region_growing([], np.ones((5,5,3)), 10, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "############################ TEST ##############################\n",
    "################################################################\n",
    "\n",
    "img_grow = plot_tumor_region_growing(img_he, region_growing, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.5 - Final Comparison (1 pts)\n",
    "\n",
    "* **Q1 (1 pts)** Run the cell below. Based on your observation, which approach do you think gives the best estimation of the tumor area? (justify)\n",
    "    * **Answer**: Simple thresholding is not capable of filtering high frequency noise. One can use morphology after thresholding image in HSV space and region growing algorithms to encapsulate the targeted region more precisely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "############################ TEST ##############################\n",
    "################################################################\n",
    "\n",
    "plot_final_comparison(img_he, img_th, img_best_morpho, img_grow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2 - Sandbox [8 pts]\n",
    "\n",
    "For the second part, you will work on a new HE case without help. This time we ask you to\n",
    "* **Q1 (4 pts)**: detect and compute the area of the blood cells,\n",
    "* **Q2 (4 pts)**: detect and compute the area of the mucin.\n",
    "\n",
    "Provide your results to the function `plot_results`. See the example below. Be careful, the completely white area is not mucin. It is the slide background and should be discarded. Moreover, you can focus on the large blood cell aggregates (large red areas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_he2 = show_exo2_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M, N, C = np.shape(img_he2)\n",
    "mask_blood = np.zeros((M, N))\n",
    "mask_mucin = np.zeros((M, N))\n",
    "\n",
    "H,S,V = extract_hsv_channels(img_he2)\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.hist(H.ravel(), bins=256)\n",
    "plt.title('hue value histogram')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.hist(S.ravel(), bins=256)\n",
    "plt.title('saturation value histogram')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.hist(V.ravel(), bins=256)\n",
    "plt.title('value histogram')\n",
    "plt.show()\n",
    "\n",
    "R,G,B = extract_rgb_channels(img_he2)\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.hist(R.ravel(), bins=256)\n",
    "plt.title('red value histogram')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.hist(G.ravel(), bins=256)\n",
    "plt.title('green value histogram')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.hist(B.ravel(), bins=256)\n",
    "plt.title('blue histogram')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple thresholding in RGB space\n",
    "mask_blood = (img_he2[:,:,0]>248) & (img_he2[:,:,1]<190) & (img_he2[:,:,2]<190)\n",
    "\n",
    "# closing and removing small objects, since we focus on the large blood cell aggregates\n",
    "mask_blood = apply_closing(mask_blood, 3)\n",
    "mask_blood = remove_objects(mask_blood, 90)\n",
    "\n",
    "# making the blood pixels white\n",
    "img_he2_copy = img_he2.copy()\n",
    "img_he2_copy[mask_blood] = 255\n",
    "\n",
    "gray_img = rgb2gray(img_he2_copy)\n",
    "\n",
    "plt.imshow(gray_img)\n",
    "plt.title('Gray scale of the image after masking blood pixels as white pixels')\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.hist(gray_img.ravel(), bins=256)\n",
    "plt.title('gray_image histogram after masking blood pixels as white pixels')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# mask white pixels to black\n",
    "mask_white = gray_img[:,:]>0.9\n",
    "gray_img[mask_white] = 0\n",
    "\n",
    "plt.imshow(gray_img)\n",
    "plt.title('Gray scale of the image after masking white pixels as black pixels')\n",
    "\n",
    "\n",
    "# Find locations and corresponding grayscale values\n",
    "mask_almost_mucin = gray_img[:,:]>0.899\n",
    "some_mucin_pixel_locations = np.argwhere(mask_almost_mucin)\n",
    "grayscale_values = gray_img[mask_almost_mucin]  # Extract pixel values\n",
    "\n",
    "# Sort by grayscale intensity in descending order\n",
    "sorted_indices = np.argsort(grayscale_values)[::-1]  # Sort and reverse order\n",
    "\n",
    "# Select the top 4 brightest pixels\n",
    "num_pixels = len(sorted_indices)\n",
    "top_4_indices = sorted_indices[:min(4, num_pixels)]  # Take top 4\n",
    "selected_locations_2D = some_mucin_pixel_locations[top_4_indices]\n",
    "\n",
    "# Plot the grayscale image\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(gray_img, cmap=\"gray\")\n",
    "plt.scatter(selected_locations_2D[:, 1], selected_locations_2D[:, 0], \n",
    "            color='red', marker='o', s=100, label=\"Top 4 Brightest Pixels\")\n",
    "plt.legend()\n",
    "plt.title(\"Top 4 Brightest Pixels in Mucin Region\")\n",
    "plt.show()\n",
    "\n",
    "# making the location tuple list to put into function region_growing\n",
    "list_tuple_locations = []\n",
    "for i in range(len(selected_locations_2D)):\n",
    "    list_tuple_locations.append(tuple(selected_locations_2D[i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "############################ TEST ##############################\n",
    "################################################################\n",
    "\n",
    "# To fine tune region growing easily function result and hyperparameters are obtained and selected respectively here\n",
    "kwargs = {'threshold':0.15,'isGrayScale':True}\n",
    "mask_mucin = region_growing(list_tuple_locations,gray_img,2000,**kwargs)\n",
    "\n",
    "plot_results(img=img_he2, mask_blood=mask_blood, mask_mucin=mask_mucin)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".virtualenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
